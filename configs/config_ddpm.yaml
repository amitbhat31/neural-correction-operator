data:
  total_samples: 5000
  train_samples: 4000
  val_samples: 100
  test_samples: 900
  img_size: 64
  # circs or sl
  dataset_type: "circs"
  bfgs_iters: 350
  noise_level: 0.0
  data_path: "data/eit_images_405_350.npz"

training:
  num_epochs: 20000
  record_epoch: 400
  save_frequency: 2000
  batch_size: 128
  lr_max: 0.001
  lr_min: 0.00001
  optimizer: "adam"
  scheduler: "cosine_annealing"

ddpm:
  Nt: 400
  beta_start: 0.0001
  beta_end: 0.2
  clip_coeff: 1.01
  generate_method: "ddpm"

model:
  name: "UNet"
  embed_dim: 256
  c0: 128
  num_blocks: 4
  unet:
    down_config_template:
      - [2, "c0", 9, 1, 4]
      - ["c0", "2*c0", 3, 2, 32]
      - ["2*c0", "4*c0", 3, 2, 32]
      - ["4*c0", "8*c0", 3, 2, 32]
    
    mid_config_template:
      - ["8*c0", "8*c0", 1, 1, 32]
    
    up_config_template:
      - ["8*c0", "4*c0", 3, 2, 32, 0]
      - ["4*c0+4*c0", "2*c0", 3, 2, 32, 1]
      - ["2*c0+2*c0", "c0", 3, 2, 32, 1]
      - ["c0+c0", 1, 9, 1, 4]

system:
  device: "cuda"
  cudnn_benchmark: true
  num_workers: 1

output:
  base_dir: "runs"
  logs_dir: "logs"
  figs_dir: "figs"
  models_dir: "mdls"
  name_template: "DDPM_{dataset}_bfgs_{bfgs_iters}_res_{img_size}_noise_{noise}_Ntr_{train_samples}_maxLR_{lr_max}_minLR_{lr_min}_timesteps_{Nt}"

validation:
  enabled: true
  frequency: 400
  metrics:
    - "relative_l2_error"
    - "mse"

checkpoint:
  save: true
  load: false
  path: null
  save_optimizer: true
  save_scheduler: true

reproducibility:
  seed: 42
  deterministic: false 

sampling:
  # Data loading parameters
  start_ind: 4100
  end_ind: 4200
  batch_size: 1
  clip_coeff: 1.0
  
  # Model loading parameters
  model_path: "checkpoint"
  
  # Output parameters
  samples_path: "samples/ddpm_samples_{dataset}_{bfgs_iters}_noise_{noise}.npy"
  
  # Averaging parameters
  num_copies: 10  # Number of copies to create for each image
  save_individual_samples: false  # Whether to save individual samples in addition to averaged ones 